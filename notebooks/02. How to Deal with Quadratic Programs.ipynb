{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to Deal with Quadratic Programs\n",
    "\n",
    "'Cause they have a habit of popping up everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Quadratic Programming\n",
    "\n",
    "**A [quadratic program](https://en.wikipedia.org/wiki/Quadratic_programming) is an optimizatio problem in the form**\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_x \\left\\{\\frac{1}{2} x^T P x + q^T x \\mid Ax \\leq b \\right\\}\n",
    "$$\n",
    "\n",
    "* $x$ is a $n$-dimensional decision variable\n",
    "* $P$ is a real symmetric matrix\n",
    "* $q$ and $b$ are real vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Our optimization form is (simpler) special case of QP, in the form:**\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_x \\left\\{\\frac{1}{2} x^T P x + q^T x \\mid x \\geq 0 \\right\\}\n",
    "$$\n",
    "\n",
    "* Where $P$ is positive definite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=big>How can we solve this kind of problem?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Could we perhaps use gradient descent?<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Projected Gradient Descent\n",
    "\n",
    "Quite like G.D., but we'll take a looong route there "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Proximal Operator\n",
    "\n",
    "**It all begins with [proximal operators](https://en.wikipedia.org/wiki/Proximal_operator):**\n",
    "\n",
    "Given a closed proper convex function:\n",
    "\n",
    "$$\n",
    "f: \\mathbb{R}^n \\to \\mathbb{R} \\cup \\{+\\infty\\}\n",
    "$$\n",
    "\n",
    "We define the (scaled) _proximal operator_ ${\\bf prox}_{\\rho f}(x)$ as:\n",
    "\n",
    "$$\n",
    "{\\bf prox}_{\\rho f}(x) = \\mathop{\\rm argmin}_{x'} \\left(f(x') + \\frac{1}{2\\rho} \\|x' - x\\|_2^2\\right)\n",
    "$$\n",
    "\n",
    "Intuitively, we search for a point $x'$ that:\n",
    "\n",
    "* Reduces the function value w.r.t. $f(x)$\n",
    "* ...And is not too far from $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Proximal Point Method\n",
    "\n",
    "**The operator is the foundation for the _proximal point method_**\n",
    "\n",
    "Given a c.p.c. function $f$, we can minimizing via the simple iteration:\n",
    "\n",
    "$$\n",
    "x^{(k+1)} = {\\bf prox}_{\\rho f}(x^{(k)})\n",
    "$$\n",
    "\n",
    "The $\\rho$ parameter can also be updated, provided that:\n",
    "\n",
    "* $\\forall k : \\rho_k > 0$\n",
    "* $\\sum_{k=1}^{\\infty} \\rho_k = \\infty$\n",
    "\n",
    "**These are the same basic conditions for gradient descent convergence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Pretty cool, right?<br>**So, why haven't you (likely) ever heard about this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Most Useful Useless Algorithm\n",
    "\n",
    "**Because the proximal point method is (apparently) _useless_**\n",
    "\n",
    "Every iteration requires to solve:\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_{x'} \\left(f(x) + \\frac{1}{2\\rho} \\|x' - x\\|_2^2\\right)\n",
    "$$\n",
    "\n",
    "* This can be just as hard as minimizing $f(x)$ directly\n",
    "* ...Or even more, give the quadratic term!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**...And yet it finds some suprising uses!**\n",
    "\n",
    "* It provides a form of regularization that enhances numerical stability\n",
    "* It serves as a framework for studying many other algorithms\n",
    "* ...And as a basis for deriving other algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Proximal Gradient Method\n",
    "\n",
    "**One such offspring is the Proximal Gradient Method**\n",
    "\n",
    "Let's consider a minimization problem in the form:\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_{x} f(x) + g(x)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $f$ is c.p.c., has domain in $\\mathbb{R}$, and is _differentiable_\n",
    "* $g$ is c.p.c., has domain in $\\mathbb{R} \\cup \\{+\\infty\\}$, and is typically _non differentiable_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This type of problem is usually obtain by _splitting_ an original cost function**\n",
    "\n",
    "* The friendlier part goes in $f$\n",
    "* The nastier one in $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Proximal Gradient Method\n",
    "\n",
    "**The problem with the split cost can then be solved by iterating:**\n",
    "\n",
    "$$\n",
    "x^{(k+1)} = {\\bf prox}_{\\rho_k g} \\left(x^{(k)} - \\rho_k \\nabla f(x^{(k)}) \\right)\n",
    "$$\n",
    "\n",
    "* First we perform a gradient descent step to minimize $f$\n",
    "* ...Then one proximal step to minimize $g$ (which is usually not differentiable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**You can view the method as follows:**\n",
    "\n",
    "* We break a single proximal step in two sub-step\n",
    "* The first substep applies to $f$ and is implemented as a G.D. update\n",
    "* In fact, G.D. updates can _always_ be seen as proximal operator applications\n",
    "* The second substep applies to $g$\n",
    "\n",
    "If $\\rho_k$ is small enough, this approximates the original proximal point method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## From Proximal to Projected Gradient Descent\n",
    "\n",
    "**This method is very useful when $g$ represents the problem constraints**\n",
    "\n",
    "The feasible set $C$ defined by a constraint can be associated to the function:\n",
    "\n",
    "$$\n",
    "g_{C}(x) = \\left\\{\\begin{aligned}\n",
    "0 & \\text{ if } x \\in C \\\\\n",
    "+\\infty & \\text{ otherwise}\n",
    "\\end{aligned}\\right.\n",
    "$$\n",
    "\n",
    "* This is called the _indicator function of the constraint_\n",
    "* If the constraint defines a convex set, then $g_C$ is also convex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**However, even a convex $g$ is not differentiable!**\n",
    "\n",
    "* Hence, we cannot apply regular gradient descent\n",
    "* ...But we can use the proximal gradient method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## From Proximal to Projected Gradient Descent\n",
    "\n",
    "**Let's inspect the proximal operator for $g_C$**\n",
    "\n",
    "By definition, this is given by:\n",
    "\n",
    "$$\n",
    "{\\bf prox}_{\\rho g_C}(x) = \\mathop{\\rm argmin}_{x'} \\left( g_C(x') + \\frac{1}{2\\rho} \\|x' - x\\|_2^2 \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* However, $g_C$ is infinite on all infeasible points\n",
    "* Therefore the operator reduces to:\n",
    "\n",
    "$$\n",
    "{\\bf prox}_{\\rho g_C}(x) = \\mathop{\\rm argmin}_{x' \\in C} \\|x' - x\\|_2^2\n",
    "$$\n",
    "\n",
    "**Meaning that we find the point in $C$ that is closest to $x$, i.e. _we project $x$ on $C$_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## From Proximal to Projected Gradient Descent\n",
    "\n",
    "**Let's consider the constraints we care about, i.e. $x \\geq 0$**\n",
    "\n",
    "For these, we get:\n",
    "\n",
    "$$\n",
    "{\\bf prox}_{\\rho g_C}(x) = \\mathop{\\rm argmin}_{x' \\geq 0} \\|x' - x\\|_2^2\n",
    "$$\n",
    "\n",
    "Which can be decomposed into one problem for each $x$ component:\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_{x'_j \\geq 0} \\|x'_j - x_j\\|_2^2\n",
    "$$\n",
    "\n",
    "Which is just the same as performing a simple clipping:\n",
    "\n",
    "$$\n",
    "\\max(0, x_j)\n",
    "$$\n",
    "\n",
    "**So, in our case, projection is _very easy!_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Projected Gradient Descent\n",
    "\n",
    "**This is a visual intuition of how the method works**\n",
    "\n",
    "<center>\n",
    "    <img src='assets/pgd.png' width=65%>\n",
    "</center>\n",
    "\n",
    "* The gradient steps bring the method closer to high quality solutions\n",
    "* The projection steps restore feasibility\n",
    "* Convergence can be slow, but it does work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class='big'>Let's go back to our problem, now:</div>\n",
    "$$\n",
    "\\mathop{\\rm argmin}_x \\left\\{\\frac{1}{2} x^T P x + q^T x \\mid x \\geq 0 \\right\\}\n",
    "$$\n",
    "<center>How else could we tackle that?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Interior Point Method\n",
    "\n",
    "Actually, _an_ interior point method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Constraints as Penalties\n",
    "\n",
    "**Let's pretend there were no constraints in out problem:**\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_x \\frac{1}{2} x^T P x + q^T x\n",
    "$$\n",
    "\n",
    "Would we really solve it via gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Since $P$ is positive definite, the problem is (strongly) convex**\n",
    "\n",
    "...Which means there is a single optimal point, where the gradient is null\n",
    "\n",
    "$$\n",
    "\\nabla \\left( \\frac{1}{2} x^T P x + q^T x \\right) = x^T (P + P^T) + q = 0\n",
    "$$\n",
    "\n",
    "Solving this linear system would give the optimal solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## From Constrained to Unconstrained Problems\n",
    "\n",
    "**Could we cast the constrained problem into a unconstrained one?**\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_x \\left\\{\\frac{1}{2} x^T P x + q^T x \\mid x \\geq 0 \\right\\}\n",
    "$$\n",
    "\n",
    "We could achieve this by making sure that _violating constriants incurs a cost_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**For example, we can associate each $\\mu_j \\geq 0$ constraint to a penalty term:**\n",
    "\n",
    "$$\n",
    "x_j \\geq 0 \\longrightarrow - \\log x_j\n",
    "$$\n",
    "\n",
    "This particular type of penalty term is called a _log barrier_:\n",
    "\n",
    "* When $x_j$ approaches 0, the term approaches $+\\infty$\n",
    "* The barrier value is not defined for $x_j < 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## From Constrained to Unconstrained Problems\n",
    "\n",
    "**The resulting unconstrained formulation is:**\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_x \\frac{1}{2} x^T P x + q^T x - \\mu \\sum_{j=1}^n \\log x_j\n",
    "$$\n",
    "\n",
    "This formulation _approximates_ the original one (since $x_j = 0$ is not permitted)\n",
    "\n",
    "* As $\\mu$ gets close to 0, we get a better approximation\n",
    "* ...So that we can approximate the true solution with arbitrary precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**But how to we obtain a solution?**\n",
    "\n",
    "* Since $-\\log x_j$ is a convex function, the cost is still strongly convex\n",
    "* ...Which means we can still find the optimum by equating the gradient to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solving Problems with Log Barriers\n",
    "\n",
    "**Equating the gradient to 0 gives us:**\n",
    "\n",
    "$$\n",
    "x^T (P + P^T) + q - \\mu \\mathop{\\rm diag}(1/x) = 0\n",
    "$$\n",
    "\n",
    "...Which is a system of _non-linear_ equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The system can be solved via [the Newton-Raphson method](https://en.wikipedia.org/wiki/Newton%27s_method)**\n",
    "\n",
    "...Which is a second-order method for solving non-linear equations\n",
    "\n",
    "* The method works by finding zeros of a local linear approximation\n",
    "* It has very fast convergence...\n",
    "* ...But it is prone to numerical issues that can jeopardize convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Interior Point Method\n",
    "\n",
    "**So, to improve stability, it is common to rely on [interior point methods](https://en.wikipedia.org/wiki/Interior-point_method)**\n",
    "\n",
    "We consider a sequence of subproblems, each with a different $\\mu_k$:\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_x \\frac{1}{2} x^T P x + q^T x - \\mu_k \\sum_{j=1}^n \\log x_j\n",
    "$$\n",
    "\n",
    "* The solution of each problem is a point _inside_ the feasible region\n",
    "* The sequence $\\{\\mu_k\\}_{k=1}^\\infty$ should be non-increasing\n",
    "* ...So every problem will be a better approximation of the original one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The N.R. method is typically used to solve each subproblem**\n",
    "\n",
    "* Typically, the N.R. method is run just for one or a few iterations\n",
    "* Under some (robust) conditions, this still enables convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Interior Point Method\n",
    "\n",
    "**This is a visual intuition of how the method works**\n",
    "\n",
    "<center>\n",
    "    <img src='assets/ipm.png' width=65%>\n",
    "</center>\n",
    "\n",
    "* At every iteration, we stay inside the feasible region\n",
    "* Convergence can be very fast (and poly time, for some classes of problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## More on Interior Point Methods\n",
    "\n",
    "**Interior Point Methods form a large family**\n",
    "\n",
    "* They can support more than simple non-negativity constraints\n",
    "* E.g. linear constraints, other forms of convex constraints\n",
    "\n",
    "Effective algorithm implementations are publicly available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**One of currently fastest methods for QP is an interior point method**\n",
    "\n",
    "That is [the PIQP solver](https://github.com/PREDICT-EPFL/piqp) developed by EPFL researchers\n",
    "\n",
    "* PIQP actually combines an interior point method with a proximal point method\n",
    "* The results is very fast and stable (but rather complex) solution method\n",
    "\n",
    "This is the solver we are going to use in our implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class='big'>Proximal and Interior Point methods are special</div>\n",
    "<center>Because the show case a key point</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An Important Insight\n",
    "\n",
    "> **If you look hard enough, you'll discover that there are are _just two ways_ to deal with constraints**\n",
    "\n",
    "* You can covert constraints to _penalties_\n",
    "* ...Or you can deal with them via _projection_\n",
    "\n",
    "Both approaches attempt to simplify the original problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The penalty approach tries to make it closer to an unconstrained version**\n",
    "\n",
    "* If you go for this approach, you'll often deal with approximations\n",
    "* You'll need to be sure that the approximation is good enough\n",
    "* ...And also stable enough from a numerical point of view!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An Important Insight\n",
    "\n",
    "> **If you look hard enough, you'll discover that there are are _just two ways_ to deal with constraints**\n",
    "\n",
    "* You can covert constraints to _penalties_\n",
    "* ...Or you can deal with them via _projection_\n",
    "\n",
    "Both approaches attempt to simplify the original problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**The projection approach deals with constraints via a separate procedure**\n",
    "\n",
    "* If you go for this approach, you'll need to have one such procedure\n",
    "* Convergence speed will typically be an issue\n",
    "* ...But you can gain in precision and generality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some References\n",
    "\n",
    "**Some references, in case you want to know more**\n",
    "\n",
    "* [\"Convex Optimization\"](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf), by Boyd and Vandenberghe\n",
    "* [\"Proximal Algorithms\"](https://stanford.edu/~boyd/papers/pdf/prox_algs.pdf), by Parikh and Boyd\n",
    "* [\"An interior-point proximal method of multipliers for convex quadratic programming\"](https://link.springer.com/article/10.1007/s10589-020-00240-9), by Pougkakiotis and Gondzio"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "rise": {
   "center": false,
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
